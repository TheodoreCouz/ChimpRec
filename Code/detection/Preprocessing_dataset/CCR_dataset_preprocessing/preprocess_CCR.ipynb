{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/videos\"\n",
    "annotations_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/metadata/annotations/body_data.csv\"\n",
    "dataset_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/Chimpanzee_detection_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year   video  frame  track         x         y         w         h  \\\n",
      "1894695  2013  17.mp4      1      1  0.275000  0.303125  0.666667  0.461111   \n",
      "1894696  2013  17.mp4      2      1  0.279167  0.303125  0.662500  0.461111   \n",
      "1894697  2013  17.mp4      3      1  0.280208  0.302083  0.665625  0.462963   \n",
      "1894698  2013  17.mp4      4      1  0.284375  0.303125  0.660417  0.461111   \n",
      "1894699  2013  17.mp4      5      1  0.280208  0.303125  0.666667  0.461111   \n",
      "...       ...     ...    ...    ...       ...       ...       ...       ...   \n",
      "1910112  2013  17.mp4  11036    272  0.276042  0.109375  0.354167  0.748148   \n",
      "1910113  2013  17.mp4  11037    272  0.275000  0.110417  0.353125  0.738889   \n",
      "1910114  2013  17.mp4  11038    272  0.272917  0.110417  0.355208  0.744444   \n",
      "1910115  2013  17.mp4  11039    272  0.273958  0.109375  0.352083  0.737037   \n",
      "1910116  2013  17.mp4  11040    272  0.271875  0.111458  0.352083  0.733333   \n",
      "\n",
      "            label  \n",
      "1894695  NOTCHIMP  \n",
      "1894696  NOTCHIMP  \n",
      "1894697  NOTCHIMP  \n",
      "1894698  NOTCHIMP  \n",
      "1894699  NOTCHIMP  \n",
      "...           ...  \n",
      "1910112      JIRE  \n",
      "1910113      JIRE  \n",
      "1910114      JIRE  \n",
      "1910115      JIRE  \n",
      "1910116      JIRE  \n",
      "\n",
      "[15422 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations_path)\n",
    "print(df.loc[df[\"video\"] == \"17.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion_kept = 0.002 # approximately 1500 images\n",
    "proportion_kept = 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input: n: size of the sample\n",
    "# proportion: (proportion*100)% of the numbers in [0, n-1]\n",
    "# @outputs\n",
    "# No numbers in common between the outputs\n",
    "def segment_dataset(n, proportion):\n",
    "    # Calculate the number of elements to select based on the proportion\n",
    "    num_elements = int(n * proportion)\n",
    "    if num_elements == 0: return []\n",
    "    \n",
    "    # Generate evenly spaced numbers within the range [0, n-1]\n",
    "    step = n / num_elements\n",
    "    selected_numbers = [int(i * step) for i in range(num_elements)]\n",
    "    \n",
    "    return selected_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_video(path_to_video):\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{path_to_video}\")\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(f\"Could not open video: {path_to_video}\")\n",
    "        return 0\n",
    "    \n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video.release()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_coordinates(coord, img_width, img_height):\n",
    "\n",
    "    x, y, w, h = coord\n",
    "    \n",
    "    x1 = int(x*img_width)\n",
    "    y1 = int(y*img_width)\n",
    "    x2 = int(x*img_width+w*img_width)\n",
    "    y2 = int((y*img_width)+h*img_height)\n",
    "\n",
    "    cx = (x1 + x2) / 2\n",
    "    cy = (y1 + y2) / 2\n",
    "\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    cx_norm = cx / img_width\n",
    "    cy_norm = cy / img_height\n",
    "\n",
    "    width_norm = width / img_width\n",
    "    height_norm = height / img_height\n",
    "\n",
    "    return [cx_norm, cy_norm, width_norm, height_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(video_type, video_id, frame_number, img_dim):\n",
    "    img_W, img_H = img_dim\n",
    "    sample_id = video_id.replace(\".mp4\", \"\")\n",
    "    sub_df = df.loc[(df[\"video\"] == video_id) & (df[\"frame\"] == frame_number)]\n",
    "    output_file = f\"{dataset_path}/labels/{video_type}/{sample_id}_{frame_number}.txt\"\n",
    "\n",
    "    string_output = \"\"\n",
    "\n",
    "    for index, row in sub_df.iterrows():\n",
    "        x, y, w, h = row['x'], row['y'], row['w'], row['h']\n",
    "        cx, cy, W, H = preprocess_coordinates((x, y, w, h), img_W, img_H)\n",
    "        string_output += f\"\\n0 {cx} {cy} {W} {H}\"\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(string_output.strip())\n",
    "    file.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input:\n",
    "# type: \"train\", \"val\" or \"test\" --> indicates which part of the dataset it is\n",
    "# sample_id: name of the video with the extension\n",
    "# idxs: indexes of the images to keep\n",
    "# @output:\n",
    "# nothing, the image are saved in the output folder\n",
    "def extract_data(type, video_id):\n",
    "\n",
    "    sample_id = video_id[:-4]\n",
    "\n",
    "    output_folder = f\"{dataset_path}/images/{type}\"\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{video_id}\")\n",
    "    len_video = get_len_video(video_id)\n",
    "\n",
    "    idxs = segment_dataset(len_video, proportion_kept)\n",
    "    idxs = sorted(idxs)\n",
    "\n",
    "    for frame_count in idxs:\n",
    "        df_ = df.loc[df[\"video\"] == video_id]\n",
    "        df_ = df_.loc[df_[\"frame\"] == frame_count] # .loc[df[\"label\"] != \"NOTCHIMP\"]\n",
    "\n",
    "        # Set the video to the specific frame\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "        success, frame = video.read()\n",
    "\n",
    "        if success and df_.size != 0:\n",
    "            frame_filename = f\"{output_folder}/{sample_id}_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            \n",
    "            # extract the annotations\n",
    "            extract_metadata(type, video_id, frame_count, (frame.shape[1], frame.shape[0]))\n",
    "        # else:\n",
    "        #     print(f\"Could not read frame {frame_count} in video {video_id}\")\n",
    "        #     print(df_)\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(video_path)\n",
    "n_files = len(filenames)\n",
    "\n",
    "train_prop = 0.7\n",
    "\n",
    "numbers = list(range(n_files))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "train_video_idxs = numbers[:math.ceil(train_prop*n_files)]\n",
    "val_video_idxs = numbers[math.ceil(train_prop*n_files):]\n",
    "\n",
    "def process_dataset(video_idxs, type):\n",
    "    # progression bar added\n",
    "    for video_idx in tqdm(video_idxs, desc=f\"Processing videos: {type}\", colour=\"green\"):\n",
    "        video_id = filenames[video_idx]\n",
    "        # try:\n",
    "        #     extract_data(type, video_id)\n",
    "        # except:\n",
    "        #     print(f\"Error: {video_id}\")\n",
    "        extract_data(type, video_id)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  21%|\u001b[32m██        \u001b[0m| 4/19 [00:23<01:20,  5.38s/it]"
     ]
    }
   ],
   "source": [
    "process_dataset(train_video_idxs, \"train\")\n",
    "process_dataset(val_video_idxs, \"val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
