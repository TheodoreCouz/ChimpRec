{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "#path to append: \"./ChimpRec/Code\"\n",
    "sys.path.append(...)\n",
    "\n",
    "from chimplib.imports import os, np, Image\n",
    "from chimplib.utils import yolo_to_pixel_coord, face_to_yolo_relative_to_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the test set create for body and face detection evaluation \n",
    "test_dataset_path = ...\n",
    "#Path to image directory of this set\n",
    "images_dir = f\"{test_dataset_path}/images\"\n",
    "#Path to label directory of this set\n",
    "labels_dir = f\"{test_dataset_path}/labels/obj_train_data\"\n",
    "#path of the folder in which the dataset is to be stored\n",
    "output_dataset = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input:\n",
    "# face: face bbox in pixel format (x1, y1, x2, y2)\n",
    "# bodies: list of bounding bboxes in YOLO format (x_center, y_center, width, height)\n",
    "# width: image width in pixels\n",
    "# height: image height in pixels\n",
    "# @output:\n",
    "# bounding box of the corresponding body in pixel format (x1, y1, x2, y2) or None if not found\n",
    "def get_corresponding_body(face, bodies,  width, height):\n",
    "    fx1, fy1, fx2, fy2 = face  \n",
    "    best_body = None\n",
    "    # We look for the body with the greatest inclusion of the face\n",
    "    best_overlap = 0 \n",
    "\n",
    "    for body in bodies:\n",
    "        bx1, by1, bx2, by2 = yolo_to_pixel_coord(body, width, height)\n",
    "\n",
    "        #Check that the face is fully contained within the body\n",
    "        if bx1 <= fx1 and bx2 >= fx2 and by1 <= fy1 and by2 >= fy2:\n",
    "            #Face and body area calculation \n",
    "            face_area = (fx2 - fx1) * (fy2 - fy1)\n",
    "            body_area = (bx2 - bx1) * (by2 - by1)\n",
    "\n",
    "            # We maximize the face_area / body_area ratio to choose the body closest in size to the face, and avoid choosing a body \n",
    "            # that's too large probably not corresponding to the face \n",
    "            overlap = face_area / body_area\n",
    "            if overlap > best_overlap:\n",
    "                best_overlap = overlap\n",
    "                best_body = body \n",
    "\n",
    "    if best_body == None: \n",
    "        return None\n",
    "    return yolo_to_pixel_coord(best_body, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for root, _, files in os.walk(labels_dir):  # On ignore la liste des sous-dossiers avec \"_\"\n",
    "    for file in files:\n",
    "        faces = []\n",
    "        bodies = []\n",
    "        \n",
    "        with open(f\"{labels_dir}/{file}\", \"r\") as current_file:\n",
    "            for line in current_file:\n",
    "                values = line.strip().split(\" \")\n",
    "\n",
    "                #1 is the id assigned to body bbox annotations and 0 to face bbox annotations\n",
    "                if values[0] == \"1\":\n",
    "                    bodies.append(tuple(map(float, values[1:])))\n",
    "                elif values[0] == \"0\":\n",
    "                    faces.append(tuple(map(float, values[1:])))\n",
    "\n",
    "        #open the image corresponding to the current label file\n",
    "        img = Image.open(images_dir + f\"/{file[:-4]}.png\")\n",
    "        frame = np.array(img)\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        face_coord = None \n",
    "        body_coord = None\n",
    "        for face in faces: \n",
    "            #Find the body corresponding to the face currently being treated\n",
    "            face_coord = tuple(yolo_to_pixel_coord(face, width, height))\n",
    "            body_coord = get_corresponding_body(face_coord, bodies, width, height)\n",
    "\n",
    "            if body_coord is None: \n",
    "                continue\n",
    "\n",
    "            fx1, fy1, fx2, fy2 = face_coord\n",
    "            bx1, by1, bx2, by2 = body_coord\n",
    "\n",
    "            #crop the image around the body then save in the right place\n",
    "            cropped_body = frame[by1:by2, bx1:bx2]\n",
    "            image_pil = Image.fromarray(np.uint8(cropped_body))\n",
    "            image_pil.save(f\"{output_dataset}/images/body{counter}.png\")\n",
    "\n",
    "            #recalculate the face bbox according to the iamge crop around the body and save in the right place\n",
    "            face_yolo_coord = face_to_yolo_relative_to_body((bx1, by1, bx2, by2), (fx1, fy1, fx2, fy2))\n",
    "            with open(f\"C{output_dataset}/labels/body{counter}.txt\", \"w\") as file:\n",
    "                file.write(\"0 \" + \" \".join(map(str, face_yolo_coord))) \n",
    "            counter+= 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
