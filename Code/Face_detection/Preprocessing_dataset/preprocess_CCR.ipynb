{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "#path to append: \"./ChimpRec/Code\"\n",
    "sys.path.append(...)\n",
    "\n",
    "from chimplib.imports import pd, cv2, os, np, Image\n",
    "from chimplib.utils import yolo_to_pixel_coord, face_to_yolo_relative_to_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to CCR dataset video folder\n",
    "videos_path = ...\n",
    "#Path to CCR body annotations (body_data.csv)\n",
    "bodies_annotations_path = ...\n",
    "#Path to CCR face annotations (face_data.csv)\n",
    "faces_annotations_path = ...\n",
    "#Path to CCR frame annotations (frame_data.csv)\n",
    "frames_annotations_path = ...\n",
    "#Path to the folder where the dataset is to be created\n",
    "output_dataset_path = ...\n",
    "\n",
    "bodies_annotations = pd.read_csv(bodies_annotations_path)\n",
    "faces_annotations = pd.read_csv(faces_annotations_path)\n",
    "frames_annotations = pd.read_csv(frames_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input:\n",
    "# video_path: path to the video file\n",
    "# frame_number: frame number to extract\n",
    "# @output:\n",
    "# frame: the extracted frame in RGB format, or None if error\n",
    "def get_frame(video_path, frame_number): \n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"Erreur : Impossible de trouver {video_path}\")\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "\n",
    "        if not ret:\n",
    "            print(f\"Erreur : Impossible de lire la frame {frame_number} de {video_path}\")\n",
    "        else:\n",
    "            return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "\n",
    "# @input:\n",
    "# annot_row: annotation from the CCR dataset (pd.Series or dict)\n",
    "# box_type: type of object to crop (\"face\" or \"body\")\n",
    "# @output:\n",
    "# cropped_img: cropped image (RGB) of the object or None if frame missing\n",
    "# bbox_pixels: pixel coordinates (x1, y1, x2, y2) of the cropped bbox or None if error\n",
    "def get_cropped_object(annot_row, box_type):\n",
    "    year = annot_row[\"year\"]\n",
    "    video = annot_row[\"video\"]\n",
    "    frame_number = annot_row[\"frame\"]\n",
    "    coord = annot_row[\"x\"], annot_row[\"y\"], annot_row[\"w\"], annot_row[\"h\"]\n",
    "\n",
    "    video_path = f\"{videos_path}/{year}/{video}\"\n",
    "    frame = get_frame(video_path, frame_number)\n",
    "    if frame is None:\n",
    "        print(f\"Frame {frame_number} form {video_path} is missing.\")\n",
    "        return None, None\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    #retrieves pixel coordinates and modifies if outside image boundaries\n",
    "    x1, y1, x2, y2 = yolo_to_pixel_coord(coord, width, height, box_type=box_type)\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(width, x2), min(height, y2)\n",
    "\n",
    "    #return cropped image and coordinates\n",
    "    return frame[y1:y2, x1:x2], (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation of the dataset with 154 images per individual crop around the chimpanzees' bodies and the face bboxes adapted to the new image<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore annotations linked to NEGATIVE\n",
    "filtered_labels = faces_annotations[faces_annotations[\"label\"] != \"NEGATIVE\"][\"label\"].unique()\n",
    "\n",
    "for name in filtered_labels:\n",
    "    counter = 0\n",
    "\n",
    "    #Keep only the annotations on the face which have a corresponding labelled body\n",
    "    valid_faces = faces_annotations[faces_annotations[\"label\"] == name].merge(\n",
    "        bodies_annotations[['year', 'video', 'frame', 'label']],\n",
    "        on=['year', 'video', 'frame', 'label'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    # Keep 154 random annotations for each chimp (13 individuals so approximetely 2000 annotations kept)\n",
    "    keeped_face_annotations = valid_faces.sample(n=154, random_state=42)\n",
    "\n",
    "    for _, face in keeped_face_annotations.iterrows():\n",
    "        # Find the corresponding body annotation\n",
    "        matching_body = bodies_annotations[\n",
    "            (bodies_annotations[\"year\"] == face[\"year\"]) &\n",
    "            (bodies_annotations[\"video\"] == face[\"video\"]) &\n",
    "            (bodies_annotations[\"frame\"] == face[\"frame\"]) & \n",
    "            (bodies_annotations[\"label\"] == face[\"label\"])\n",
    "        ]\n",
    "\n",
    "        if matching_body.empty:\n",
    "            print(counter)\n",
    "            continue\n",
    "\n",
    "        \n",
    "        cropped_body, body_coord = get_cropped_object(matching_body, \"body\")\n",
    "        cropped_face, face_coord = get_cropped_object(face, \"face\")\n",
    "\n",
    "        face_relative_to_body = face_to_yolo_relative_to_body(body_coord, face_coord)\n",
    "\n",
    "        #save image\n",
    "        image_pil = Image.fromarray(np.uint8(cropped_body))\n",
    "        image_path = f\"{output_dataset_path}images/train/{name}{counter}.png\"\n",
    "        image_pil.save(image_path)\n",
    "\n",
    "        #save annotations\n",
    "        label_path = f\"{output_dataset_path}/labels/train/{name}{counter}.txt\"\n",
    "        with open(label_path, \"w\") as file:\n",
    "            file.write(\"0 \" + \" \".join(map(str, face_relative_to_body)))\n",
    "\n",
    "        counter += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
