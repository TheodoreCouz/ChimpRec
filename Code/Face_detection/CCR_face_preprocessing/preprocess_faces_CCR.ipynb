{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/videos\"\n",
    "annotations_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/metadata/annotations/face_data.csv\"\n",
    "dataset_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/Face_detection_CCR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of the overall dataset that will be kept\n",
    "proportion_kept = 0.003 # approximately 1500 images\n",
    "\n",
    "df = pd.read_csv(annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input: n: size of the sample\n",
    "# proportion: (proportion*100)% of the numbers in [0, n-1]\n",
    "# @outputs\n",
    "# No numbers in common between the outputs\n",
    "def segment_dataset(n, proportion):\n",
    "    # Calculate the number of elements to select based on the proportion\n",
    "    num_elements = int(n * proportion)\n",
    "    \n",
    "    # Generate evenly spaced numbers within the range [0, n-1]\n",
    "    step = n / num_elements\n",
    "    selected_numbers = [int(i * step) for i in range(num_elements)]\n",
    "    \n",
    "    return selected_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input: path to a video\n",
    "# @outputs\n",
    "# Length of the video in terms of frames\n",
    "def get_len_video(path_to_video):\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{path_to_video}\")\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(f\"Could not open video: {path_to_video}\")\n",
    "        return 0\n",
    "    \n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video.release()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the annotation data\n",
    "def extract_metadata(video_type, video_id, frame_number, img_dim):\n",
    "    sample_id = video_id.replace(\".mp4\", \"\")\n",
    "    sub_df = df.loc[(df[\"video\"] == video_id) & (df[\"frame\"] == frame_number)]\n",
    "    output_file = f\"{dataset_path}/labels/{video_type}/{sample_id}_{frame_number}.txt\"\n",
    "\n",
    "    string_output = \"\"\n",
    "\n",
    "    for index, row in sub_df.iterrows():\n",
    "        string_output += f\"\\n0 {row['x']} {row['y']} {row['w']} {row['h']}\"\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(string_output.strip())\n",
    "    file.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input:\n",
    "# type: \"train\", \"val\" or \"test\" --> indicates which part of the dataset it is\n",
    "# sample_id: name of the video with the extension\n",
    "# idxs: indexes of the images to keep\n",
    "# @output:\n",
    "# nothing, the image are saved in the output folder\n",
    "def extract_data(type, video_id):\n",
    "\n",
    "    sample_id = video_id[:-4]\n",
    "\n",
    "    output_folder = f\"{dataset_path}/images/{type}\"\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{video_id}\")\n",
    "    len_video = get_len_video(video_id)\n",
    "\n",
    "    idxs = segment_dataset(len_video, proportion_kept)\n",
    "    idxs = sorted(idxs)\n",
    "\n",
    "    for frame_count in idxs:\n",
    "        df_ = df.loc[df[\"video\"] == video_id]\n",
    "        df_ = df_.loc[df_[\"frame\"] == frame_count] # .loc[df[\"label\"] != \"NOTCHIMP\"]\n",
    "\n",
    "        # Set the video to the specific frame\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "        success, frame = video.read()\n",
    "\n",
    "        if success and df_.size != 0:\n",
    "            frame_filename = f\"{output_folder}/{sample_id}_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            \n",
    "            # extract the annotations\n",
    "            extract_metadata(type, video_id, frame_count, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(video_path)[:2] #only consider the first two videos (can ofc be changed)\n",
    "n_files = len(filenames)\n",
    "\n",
    "# training proportion\n",
    "train_prop = 0.5\n",
    "\n",
    "numbers = list(range(n_files))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "train_video_idxs = numbers[:math.ceil(train_prop*n_files)]\n",
    "val_video_idxs = numbers[math.ceil(train_prop*n_files):]\n",
    "\n",
    "def process_dataset(video_idxs, type):\n",
    "    # progression bar added\n",
    "    for video_idx in tqdm(video_idxs, desc=f\"Processing videos: {type}\", colour=\"green\"):\n",
    "        video_id = filenames[video_idx]\n",
    "        extract_data(type, video_id)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train: 100%|\u001b[32m██████████\u001b[0m| 1/1 [00:27<00:00, 27.96s/it]\n",
      "Processing videos: val: 100%|\u001b[32m██████████\u001b[0m| 1/1 [00:03<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_video_idxs, \"train\")\n",
    "process_dataset(val_video_idxs, \"val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
