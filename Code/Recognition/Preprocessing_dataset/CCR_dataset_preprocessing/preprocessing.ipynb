{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dataset adapté pour utiliser le model de reconnaissance sur le dataset CCR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = \"C:/Users/julie/OneDrive - UCL/Master_2/Mémoire/ChimpRec/ChimpRec-Dataset/CCR/data/videos\"\n",
    "annotations_path = \"C:/Users/julie/OneDrive - UCL/Master_2/Mémoire/ChimpRec/ChimpRec-Dataset/CCR/annotations/face_data.csv\"\n",
    "dataset_path = \"C:/Users/julie/Documents/Unif/Mémoire/CCR_recognition_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_resolution(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "    return width, height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JEJE\n",
      "PELEY\n",
      "FANLE\n",
      "TUA\n",
      "FANWA\n",
      "FANA\n",
      "JIRE\n",
      "JOYA\n",
      "FLANLE\n",
      "FOAF\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations_path)\n",
    "\n",
    "individuals_name = list(df['label'].unique())\n",
    "for name in ['NEGATIVE', 'VELU', 'PAMA', 'YO']:\n",
    "    if name in individuals_name:\n",
    "        individuals_name.remove(name)\n",
    "\n",
    "videos_resolution = {}\n",
    "for video in list(df['video'].unique()): \n",
    "    year = 0\n",
    "    if video in os.listdir(os.path.join(videos_path, \"2012\")): \n",
    "        year = 2012\n",
    "    else: \n",
    "        year = 2013\n",
    "    videos_resolution[video] = get_video_resolution(os.path.join(videos_path, str(year), video))\n",
    "\n",
    "data_split = {}\n",
    "\n",
    "for individual in individuals_name:\n",
    "    print(individual)\n",
    "    videos = list(df[df['label'] == individual]['video'].unique())\n",
    "    random.shuffle(videos)\n",
    "\n",
    "    # Répartition 70% train, 15% validation, 15% test\n",
    "    train_videos = videos[:int(0.7 * len(videos))]\n",
    "    val_videos = videos[int(0.7 * len(videos)):int(0.85 * len(videos))]\n",
    "    test_videos = videos[int(0.85 * len(videos)):]\n",
    "\n",
    "    # Filtrer les crops trop petits\n",
    "    df_individual = df[df['label'] == individual].copy()\n",
    "\n",
    "    #Ne garder que les crop assez grands\n",
    "    valid_rows = []\n",
    "    for _, row in df_individual.iterrows():\n",
    "        width, height = videos_resolution[row[\"video\"]]\n",
    "        crop_width = row['w'] * width\n",
    "        crop_height = row['h'] * height\n",
    "\n",
    "        if crop_width > 100 and crop_height > 100:\n",
    "            valid_rows.append(row)\n",
    "\n",
    "    df_filtered = pd.DataFrame(valid_rows)\n",
    "\n",
    "    train_subset = df_filtered[df_filtered['video'].isin(train_videos)]\n",
    "    \n",
    "    #Si y a pas assez d'image dans le test set ou le validation set, on va en prendre dans le train set\n",
    "    val_subset = df_filtered[df_filtered['video'].isin(val_videos)]\n",
    "    if len(val_subset) < 250: \n",
    "        extra_val_images = train_subset.sample(n=250-len(val_subset), random_state=42, replace=False)\n",
    "        val_subset = pd.concat([val_subset, extra_val_images])\n",
    "        train_subset = train_subset.drop(extra_val_images.index) \n",
    "\n",
    "    test_subset = df_filtered[df_filtered['video'].isin(test_videos)]\n",
    "    if len(test_subset) < 250: \n",
    "        extra_test_images = train_subset.sample(n=250-len(test_subset), random_state=42, replace=False)\n",
    "        test_subset = pd.concat([test_subset, extra_test_images])\n",
    "        train_subset = train_subset.drop(extra_test_images.index) \n",
    "\n",
    "    # Vérification pour éviter l'erreur\n",
    "    train_frames = train_subset.sample(n=1000, random_state=42, replace=False)\n",
    "    val_frames = val_subset.sample(n=250, random_state=42, replace=False)\n",
    "    test_frames = test_subset.sample(n=250, random_state=42, replace=False)\n",
    "\n",
    "    # Stocker les résultats\n",
    "    data_split[individual] = {\n",
    "        \"train\": train_frames,\n",
    "        \"validation\": val_frames,\n",
    "        \"test\": test_frames\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire et sauvegarder les images\n",
    "def save_cropped_faces(data, split):\n",
    "    for individual, frames in data.items():\n",
    "        split_path = os.path.join(dataset_path, split)\n",
    "\n",
    "        if split in [\"train\", \"val\"]:\n",
    "            individual_path = os.path.join(split_path, individual)\n",
    "            os.makedirs(individual_path, exist_ok=True)\n",
    "        else:\n",
    "            individual_path = split_path\n",
    "\n",
    "        id  = 0\n",
    "\n",
    "        for idx, row in frames.iterrows():\n",
    "            video_path = os.path.join(videos_path, str(row[\"year\"]), row[\"video\"])\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            if not cap.isOpened():\n",
    "                print(f\"+Erreur ouverture vidéo : {row['video']}\")\n",
    "                continue\n",
    "\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, row[\"frame\"])\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret or frame is None:\n",
    "                print(f\"Impossible de lire la frame {row['frame']} de {row['video']}\")\n",
    "                cap.release()\n",
    "                continue\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "            h, w, _ = frame.shape\n",
    "            x1 = int(row[\"x\"] * w)\n",
    "            y1 = int(row[\"y\"] * h)\n",
    "            x2 = x1 + int(row[\"w\"] * w)\n",
    "            y2 = y1 + int(row[\"h\"] * h)\n",
    "\n",
    "            # Correction des bords\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(w, x2), min(h, y2)\n",
    "\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Vérification si le crop est vide\n",
    "            if face_crop is None or face_crop.size == 0:\n",
    "                print(f\"face_crop vide pour {row['video']} frame {row['frame']}\")\n",
    "                continue\n",
    "\n",
    "            face_crop = face_crop.astype(np.uint8)  # Correction de type\n",
    "            \"\"\"plt.imshow(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB))  # Convertir BGR → RGB\n",
    "            plt.axis(\"off\")  # Cacher les axes\n",
    "            plt.show()\"\"\"\n",
    "\n",
    "            filename = f\"{individual}_{id}.jpg\"\n",
    "            id += 1\n",
    "\n",
    "            filepath = os.path.join(individual_path, filename)\n",
    "            image_pil = Image.fromarray(np.uint8(face_crop))\n",
    "            image_pil.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les dossiers si inexistants\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_path = os.path.join(dataset_path, split)\n",
    "    os.makedirs(split_path, exist_ok=True)\n",
    "\n",
    "# Sauvegarde des images\n",
    "save_cropped_faces({k: v[\"train\"] for k, v in data_split.items()}, \"train\")\n",
    "save_cropped_faces({k: v[\"validation\"] for k, v in data_split.items()}, \"val\")\n",
    "save_cropped_faces({k: v[\"test\"] for k, v in data_split.items()}, \"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
