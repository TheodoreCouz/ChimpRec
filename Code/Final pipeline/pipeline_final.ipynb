{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model paths</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = YOLO(\"/home/theo/Documents/Unif/Master/ChimpRec/Code/Body_detection/YOLO_small/runs/detect/train9/weights/best.pt\")\n",
    "model_2 = YOLO(\"/home/theo/Documents/Unif/Master/ChimpRec/Code/Face_detection/runs/detect/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Video paths</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/theo/Documents/Unif/Master/Chimprec - Extra/videos/20241023 - 09h28.MP4\"\n",
    "output_path = \"output.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First prediction in the pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using the body detection model\n",
    "def predict_1(image, t_confidence=0.4):\n",
    "    results = model_1.predict(image, verbose=False)[0]\n",
    "    return tuple(\n",
    "        (x1, y1, x2, y2, score)\n",
    "        for x1, y1, x2, y2, score, _ in results.boxes.data.tolist()\n",
    "        if score >= t_confidence\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Second prediction in the pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction using the face detection model\n",
    "def predict_2(image, t_confidence=0.6):\n",
    "    results = model_2.predict(image, verbose=False)\n",
    "    best = max(\n",
    "        (\n",
    "            (int(x1), int(y1), int(x2), int(y2), score)\n",
    "            for result in results\n",
    "            for x1, y1, x2, y2, score, _ in result.boxes.data.tolist()\n",
    "        ),\n",
    "        default=None,\n",
    "        key=lambda x: x[-1]\n",
    "    )\n",
    "    return best if best and best[-1] >= t_confidence else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Util functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a cropped image within image according to bbox\n",
    "def crop(image, bbox):\n",
    "    x1, y1, x2, y2, _ = map(int, bbox)\n",
    "    return image[max(y1, 0):y2, max(x1, 0):x2]\n",
    "\n",
    "# converts the bbox from the cropped body image into coordinates in the initial image\n",
    "def face_to_src(body_bbox, face_bbox):\n",
    "    bx1, by1, _, _, _ = body_bbox\n",
    "    fx1, fy1, fx2, fy2, score = face_bbox\n",
    "    return (int(bx1 + fx1), int(by1 + fy1), int(bx1 + fx2), int(by1 + fy2), score)\n",
    "\n",
    "# draw bbox on image\n",
    "def draw_bbox(image, color, bbox, label):\n",
    "    x1, y1, x2, y2, score = bbox\n",
    "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "    factor = 0.65 if label == \"Face\" else 0.3\n",
    "    font_scale = max(0.4, (x2 - x1 + y2 - y1) / 300) * factor\n",
    "\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, 4)\n",
    "    label_text = f\"{label}: {score:.2f}\"\n",
    "    (w, h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_COMPLEX, font_scale, 1)\n",
    "\n",
    "    overlay = image.copy()\n",
    "    cv2.rectangle(overlay, (x2 - w - 10, y2 - h - 10), (x2, y2), color, -1)\n",
    "    cv2.addWeighted(overlay, 0.5, image, 0.5, 0, image)\n",
    "\n",
    "    cv2.putText(image, label_text, (x2 - w - 5, y2 - 5), cv2.FONT_HERSHEY_COMPLEX, font_scale, (255,255,255), 1)\n",
    "    return image\n",
    "\n",
    "# extract the body and face bboxes from image\n",
    "def predict_frame(image, body_bboxes=None, face_bboxes=None):\n",
    "    if body_bboxes is None:\n",
    "        body_bboxes = predict_1(image)\n",
    "        face_bboxes = tuple(\n",
    "            face_to_src(body_bbox, face_bbox)\n",
    "            for body_bbox in body_bboxes\n",
    "            if (face_bbox := predict_2(crop(image, body_bbox))) is not None\n",
    "        )\n",
    "\n",
    "    for bbox in body_bboxes:\n",
    "        draw_bbox(image, (254, 122, 51), bbox, \"Body\")\n",
    "    for bbox in face_bboxes:\n",
    "        draw_bbox(image, (66, 66, 255), bbox, \"Face\")\n",
    "\n",
    "    return image, body_bboxes, face_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Main code</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 120/120 [00:22<00:00,  5.31it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 3  # Process one frame every n frames\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "max_frames = 120#int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "body_bboxes, face_bboxes = None, None\n",
    "\n",
    "with tqdm(total=max_frames, desc=\"Processing frames\") as pbar:\n",
    "    for frame_idx in range(max_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % n == 0:\n",
    "            annotated_frame, body_bboxes, face_bboxes = predict_frame(frame)\n",
    "        else:\n",
    "            annotated_frame, _, _ = predict_frame(frame, body_bboxes, face_bboxes)\n",
    "\n",
    "        out.write(annotated_frame)\n",
    "        pbar.update(1)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
