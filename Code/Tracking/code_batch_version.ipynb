{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>File paths and imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Theo/Documents/Unif/ChimpRec/Code\")\n",
    "\n",
    "from chimplib.imports import *\n",
    "from chimplib.tracking_manual_correction import *\n",
    "\n",
    "# path of the model\n",
    "model_path = \"C:/Users/Theo/Documents/Unif/Models/body/v8s/weights/best.pt\"\n",
    "\n",
    "# video paths:\n",
    "# input video directory (without any annotation)\n",
    "input_video_directory = \"C:/Users/Theo/Documents/Unif/chimprec-videos/input_videos\"\n",
    "# output (final version - with human interaction)\n",
    "output_video_directory = \"C:/Users/Theo/Documents/Unif/chimprec-videos/output_videos\"\n",
    "# directory containing all the manual modifications\n",
    "\n",
    "mannual_annotations_directory = f\"{input_video_directory}/manual_annotations\"\n",
    "output_video_directory_temp = f\"{output_video_directory}/temp\"\n",
    "raw_text_output_directory = f\"{output_video_directory_temp}/raw_output\"\n",
    "\n",
    "# Create the directories if they do not exist yet\n",
    "os.makedirs(input_video_directory, exist_ok=True)\n",
    "os.makedirs(output_video_directory, exist_ok=True)\n",
    "os.makedirs(mannual_annotations_directory, exist_ok=True)\n",
    "os.makedirs(output_video_directory_temp, exist_ok=True)\n",
    "os.makedirs(raw_text_output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>First step:</h2>\n",
    "<h3>Processing the raw video without annotation and produce a textual output (stored in <i>input_text_file_path</i>) and a visual output (accessible via <i>output_video_path</i>).</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cosine_distance = 0.5       # maximal distance to match an object (lower = more strict)\n",
    "nn_budget = None                # maximal buffer size\n",
    "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "\n",
    "# YOLOv8s initialisation\n",
    "YOLOv8s = YOLO(model_path)\n",
    "\n",
    "# DeepSORT initialisation\n",
    "DeepSort = DeepSortTracker(metric)\n",
    "\n",
    "# Osnet initialisation\n",
    "Osnet = torchreid.models.build_model(name='osnet_x1_0', num_classes=751, pretrained=True)\n",
    "Osnet.eval()\n",
    "\n",
    "for input_video in os.listdir(input_video_directory):\n",
    "    if input_video.endswith(\".mp4\") or input_video.endswith(\".MP4\"):\n",
    "\n",
    "        full_video_path = os.path.join(input_video_directory, input_video)\n",
    "        video_name = os.path.splitext(input_video)[0]\n",
    "\n",
    "        # production of the textual outputs\n",
    "        perform_tracking(\n",
    "            input_video_path = full_video_path, \n",
    "            output_text_file_path = f\"{raw_text_output_directory}/{video_name}.txt\", \n",
    "            detection_model = YOLOv8s, \n",
    "            tracker = DeepSort,\n",
    "            confidence_threshold = 0.5, \n",
    "            model_feature_extraction = Osnet\n",
    "        )\n",
    "        print(f\"Annotations ready for video: {full_video_path}\")\n",
    "\n",
    "        # production of the visual output\n",
    "        draw_bbox_from_file(\n",
    "            file_path = f\"{raw_text_output_directory}/{video_name}.txt\", \n",
    "            input_video_path = full_video_path, \n",
    "            output_video_path = f\"{output_video_directory_temp}/{video_name}-(temp).mp4\",\n",
    "            annotation_type=\"bbox\",\n",
    "            draw_frame_count=True\n",
    "        )\n",
    "        print(f\"Treatment done: {full_video_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Third step:</h2>\n",
    "<h3>Processing the output of the two first steps to produce a textual output (stored in <i>output_text_file_path</i>) and a visual output (accessible via <i>output_edited_video_path</i>).</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_video in os.listdir(input_video_directory):\n",
    "    if input_video.endswith(\".mp4\") or input_video.endswith(\".MP4\"):\n",
    "        full_video_path = os.path.join(input_video_directory, input_video)\n",
    "        video_name = os.path.splitext(input_video)[0]\n",
    "        annotation_file = f\"{mannual_annotations_directory}/{video_name}.txt\"\n",
    "\n",
    "        raw_reader = raw_tracking_data_reader(f\"{raw_text_output_directory}/{video_name}.txt\")\n",
    "\n",
    "        try:\n",
    "            edit_reader = modification_reader(annotation_file)\n",
    "        except:\n",
    "            print(f\"Error: the manual annotation file related to the video <{full_video_path}> is not found. It must be located at <{annotation_file}>.\")\n",
    "            continue\n",
    "        \n",
    "        metadata_file_path = f\"{output_video_directory}/{video_name}-treated.txt\"\n",
    "        output_video_path = f\"{output_video_directory}/{video_name}-treated.mp4\"\n",
    "        writer = data_writer(metadata_file_path)\n",
    "\n",
    "        # computation of the new metadata file\n",
    "        modified_data = edit_raw_output(raw_reader, edit_reader) \n",
    "\n",
    "        # production of the textual output\n",
    "        writer.write(modified_data)\n",
    "\n",
    "        # production of the visual output\n",
    "        draw_bbox_from_file(\n",
    "            file_path = metadata_file_path, \n",
    "            input_video_path = full_video_path, \n",
    "            output_video_path = output_video_path,\n",
    "            annotation_type=\"triangle\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
