{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (2.31.0)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from facenet-pytorch) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2024.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\julie\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\julie\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import InceptionResnetV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle implémente ce qui est décrit dans \"FaceNet: A Unified Embedding for Face Recognition and Clustering\". Cependant il est pré-entraîné donc il faudrait le retrain grâce à des triplets fait sur base des chimpanzés qu'on doit reconnaître. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111M/111M [00:11<00:00, 10.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé avec succès !\n"
     ]
    }
   ],
   "source": [
    "model = InceptionResnetV1(pretrained='casia-webface', classify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà comment réentrainer le model grâce au dataset de chimpanzé. Il faut juste modifier la création des triplets pour utiliser une des techniques mentionnées dans l'article (j'opterais plus pour la méthode dynamique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import models\n",
    "from facenet_pytorch import training\n",
    "\n",
    "# Charger le modèle pré-entraîné InceptionResnetV1 sans classification\n",
    "model = InceptionResnetV1(pretrained='casia-webface', classify=False).eval()\n",
    "\n",
    "# Préparer les transformations pour les images (normalisation des pixels, redimensionnement)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Redimensionner les images à 160x160\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # Normalisation\n",
    "])\n",
    "\n",
    "# Charger le dataset (remplacer le chemin par le vôtre)\n",
    "dataset = datasets.ImageFolder(root='/path/to/your/dataset', transform=transform)\n",
    "\n",
    "# Créer un DataLoader pour itérer sur le dataset pendant l'entraînement\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Fonction de création de triplets\n",
    "# Cette fonction crée des triplets à partir des images du dataset\n",
    "def create_triplets(dataset, batch_size=32):\n",
    "    # Exemple de génération de triplets. Vous pouvez personnaliser cette fonction\n",
    "    # pour la rendre plus efficace et adaptée à vos besoins\n",
    "    triplets = []\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        anchor_image = dataset[i]\n",
    "        positive_image = dataset[i + 1]  # Trouver un positif dans le même sous-dossier\n",
    "        negative_image = dataset[(i + 2) % len(dataset)]  # Trouver un négatif dans un sous-dossier différent\n",
    "        triplets.append((anchor_image, positive_image, negative_image))\n",
    "    return triplets\n",
    "\n",
    "# Créer une boucle d'entraînement\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Mode entraînement\n",
    "    for batch in dataloader:\n",
    "        images, _ = batch  # Obtenir les images\n",
    "        triplets = create_triplets(images)  # Créer des triplets à partir du lot\n",
    "\n",
    "        # Séparer les triplets en ancres, positifs et négatifs\n",
    "        anchor, positive, negative = triplets\n",
    "\n",
    "        # Calculer les embeddings\n",
    "        anchor_embedding = model(anchor)\n",
    "        positive_embedding = model(positive)\n",
    "        negative_embedding = model(negative)\n",
    "\n",
    "        # Calculer la triplet loss\n",
    "        loss = torch.nn.functional.triplet_margin_loss(anchor_embedding, positive_embedding, negative_embedding, margin=1.0)\n",
    "\n",
    "        # Mise à jour des poids\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Sauvegarder le modèle fine-tuné\n",
    "torch.save(model.state_dict(), 'retrained_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
