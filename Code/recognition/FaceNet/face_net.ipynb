{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import InceptionResnetV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : {'FANLE': 0, 'FANWA': 1, 'FLANLE': 2, 'JEJE': 3, 'JOYA': 4, 'PELEY': 5}\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../../../ChimpRec-Dataset/Chimpanzee_recognition_dataset\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(10),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(dataset_path, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(dataset_path, \"val\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=400, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "class_to_idx = train_dataset.class_to_idx\n",
    "print(\"Classes :\", class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On gèle toutes les couches sauf la dernière afin que les poids calculés pour les couches précédentes sur base de l'entraînement qui a été fait avec vggface restent les mêmes et qu'on ne modifie que la dernière couche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geler toutes les couches sauf les 5 dernières\n",
    "for param in facenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\"\"\"for param in facenet.last_linear.parameters():\n",
    "    param.requires_grad = True\"\"\"\n",
    "for layer in list(facenet.children())[-3:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"num_classes = len(class_to_idx)\n",
    "facenet.classify = True\n",
    "facenet.last_linear = nn.Linear(facenet.last_linear.in_features, num_classes)\"\"\"\n",
    "\n",
    "# Déplacer le modèle sur GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "facenet = facenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(facenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "-----------------------\n",
      "Train Loss: 6.1975 Acc: 0.0574\n",
      "Val Loss: 6.1612 Acc: 0.2833\n",
      "\n",
      "Epoch 2/20\n",
      "-----------------------\n",
      "Train Loss: 6.1740 Acc: 0.1724\n",
      "Val Loss: 6.1493 Acc: 0.3600\n",
      "\n",
      "Epoch 3/20\n",
      "-----------------------\n",
      "Train Loss: 6.1473 Acc: 0.3217\n",
      "Val Loss: 6.1264 Acc: 0.4367\n",
      "\n",
      "Epoch 4/20\n",
      "-----------------------\n",
      "Train Loss: 6.1149 Acc: 0.4417\n",
      "Val Loss: 6.0984 Acc: 0.4950\n",
      "\n",
      "Epoch 5/20\n",
      "-----------------------\n",
      "Train Loss: 6.0849 Acc: 0.5233\n",
      "Val Loss: 6.0752 Acc: 0.5483\n",
      "\n",
      "Epoch 6/20\n",
      "-----------------------\n",
      "Train Loss: 6.0662 Acc: 0.5600\n",
      "Val Loss: 6.0536 Acc: 0.5700\n",
      "\n",
      "Epoch 7/20\n",
      "-----------------------\n",
      "Train Loss: 6.0578 Acc: 0.5717\n",
      "Val Loss: 6.0295 Acc: 0.6100\n",
      "\n",
      "Epoch 8/20\n",
      "-----------------------\n",
      "Train Loss: 6.0381 Acc: 0.5939\n",
      "Val Loss: 6.0194 Acc: 0.6167\n",
      "\n",
      "Epoch 9/20\n",
      "-----------------------\n",
      "Train Loss: 6.0277 Acc: 0.5974\n",
      "Val Loss: 6.0114 Acc: 0.6467\n",
      "\n",
      "Epoch 10/20\n",
      "-----------------------\n",
      "Train Loss: 6.0194 Acc: 0.6083\n",
      "Val Loss: 6.0015 Acc: 0.6500\n",
      "\n",
      "Epoch 11/20\n",
      "-----------------------\n",
      "Train Loss: 6.0110 Acc: 0.6185\n",
      "Val Loss: 5.9955 Acc: 0.6583\n",
      "\n",
      "Epoch 12/20\n",
      "-----------------------\n",
      "Train Loss: 6.0028 Acc: 0.6269\n",
      "Val Loss: 5.9856 Acc: 0.6650\n",
      "\n",
      "Epoch 13/20\n",
      "-----------------------\n",
      "Train Loss: 5.9883 Acc: 0.6354\n",
      "Val Loss: 5.9868 Acc: 0.6633\n",
      "\n",
      "Epoch 14/20\n",
      "-----------------------\n",
      "Train Loss: 5.9889 Acc: 0.6404\n",
      "Val Loss: 5.9689 Acc: 0.6583\n",
      "\n",
      "Epoch 15/20\n",
      "-----------------------\n",
      "Train Loss: 5.9749 Acc: 0.6481\n",
      "Val Loss: 5.9644 Acc: 0.6583\n",
      "\n",
      "Epoch 16/20\n",
      "-----------------------\n",
      "Train Loss: 5.9695 Acc: 0.6463\n",
      "Val Loss: 5.9542 Acc: 0.6650\n",
      "\n",
      "Epoch 17/20\n",
      "-----------------------\n",
      "Train Loss: 5.9676 Acc: 0.6452\n",
      "Val Loss: 5.9435 Acc: 0.6617\n",
      "\n",
      "Epoch 18/20\n",
      "-----------------------\n",
      "Train Loss: 5.9615 Acc: 0.6385\n",
      "Val Loss: 5.9350 Acc: 0.6617\n",
      "\n",
      "Epoch 19/20\n",
      "-----------------------\n",
      "Train Loss: 5.9484 Acc: 0.6552\n",
      "Val Loss: 5.9277 Acc: 0.6750\n",
      "\n",
      "Epoch 20/20\n",
      "-----------------------\n",
      "Train Loss: 5.9335 Acc: 0.6650\n",
      "Val Loss: 5.9227 Acc: 0.6900\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            #Pour remettre les gradients à 0 car par défaut avec pytorch ils s'accumulent donc si on fait pas ça les \n",
    "            # gradients de cette étape d’entraînement s'ajouteront à ceux de l'étape précédente\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward() #calcule le gradients des param \n",
    "            optimizer.step() #optimise les param en fonction des gardients \n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Phase de validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_corrects / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
    "\n",
    "\n",
    "train_model(facenet, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
    "\n",
    "torch.save(facenet.state_dict(), \"facenet_chimpanzee_finetuned.pth\")\n",
    "#print(\"Modèle sauvegardé.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour charger le modèle ensuite: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet_loaded = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "facenet_loaded.load_state_dict(torch.load(\"facenet_chimpanzee_finetuned.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "facenet_loaded = facenet_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite : FANWA\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Charger et transformer l'image\n",
    "def predict_image(image_path, model, transform, class_to_idx, device):\n",
    "    model.eval()\n",
    "    \n",
    "    # Charger l'image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Appliquer les transformations\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)  # Ajouter une dimension pour le batch\n",
    "    \n",
    "    # Effectuer une prédiction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted_idx = torch.max(outputs, 1)  # Trouver l'indice de la classe prédite\n",
    "    \n",
    "    # Récupérer le label correspondant\n",
    "    idx_to_class = {v: k for k, v in class_to_idx.items()}\n",
    "    predicted_class = idx_to_class[predicted_idx.item()]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path = \"../../../ChimpRec-Dataset/Chimpanzee_recognition_dataset/val/JEJE/JEJE_12.jpg\"\n",
    "predicted_class = predict_image(image_path, facenet_loaded, transform, class_to_idx, device)\n",
    "print(f\"Classe prédite : {predicted_class}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
