{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from itertools import combinations\n",
    "import random\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../../ChimpRec-Dataset/Chimpanzee_recognition_dataset\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for img, label in self.dataset:\n",
    "            self.data.append(img)\n",
    "            self.labels.append(label)\n",
    "        self.labels = torch.tensor(self.labels)\n",
    "        self.classes = torch.unique(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_img = self.data[idx]\n",
    "        anchor_label = self.labels[idx]\n",
    "        \n",
    "        #On prend un exemple positif et un négatif par rapport à l'anchor (random pour l'instant)\n",
    "        positive_indices = torch.where(self.labels == anchor_label)[0]\n",
    "        negative_indices = torch.where(self.labels != anchor_label)[0]\n",
    "\n",
    "        positive_idx = random.choice(positive_indices)\n",
    "        negative_idx = random.choice(negative_indices)\n",
    "\n",
    "        positive_img = self.data[positive_idx]\n",
    "        negative_img = self.data[negative_idx]\n",
    "\n",
    "        return anchor_img, positive_img, negative_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TripletDataset(\n",
    "    datasets.ImageFolder(os.path.join(dataset_path, \"train\"), transform=transform),\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = TripletDataset(\n",
    "    datasets.ImageFolder(os.path.join(dataset_path, \"val\"), transform=transform),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "facenet = InceptionResnetV1(pretrained='vggface2').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Débloquer les dernières couches\n",
    "for param in facenet.parameters():\n",
    "    param.requires_grad = False\n",
    "for layer in list(facenet.children())[-5:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Déplacer le modèle sur GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "facenet = facenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = optim.Adam(facenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for anchor, positive, negative in train_loader:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_output = model(anchor)\n",
    "            positive_output = model(positive)\n",
    "            negative_output = model(negative)\n",
    "\n",
    "            loss = criterion(anchor_output, positive_output, negative_output)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for anchor, positive, negative in val_loader:\n",
    "                anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "                anchor_output = model(anchor)\n",
    "                positive_output = model(positive)\n",
    "                negative_output = model(negative)\n",
    "\n",
    "                loss = criterion(anchor_output, positive_output, negative_output)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "train_model(facenet, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour prédire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_embedding_label(model, train_loader, device, k=5):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in train_loader.dataset.dataset:\n",
    "            inputs = inputs.to(device).unsqueeze(0)\n",
    "            embedding = model(inputs).cpu().squeeze().numpy()\n",
    "            embeddings.append(embedding)\n",
    "            labels.append(targets)\n",
    "\n",
    "    embeddings = np.array(embeddings)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(embeddings, labels)\n",
    "\n",
    "    print(f\"Training embeddings and k-NN completed. k-NN trained with {len(labels)} samples.\")\n",
    "    return knn, embeddings, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, knn, image_path, transform, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    image = transform(image).unsqueeze(0)  \n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        embedding = model(image).cpu().squeeze().numpy()\n",
    "\n",
    "    predicted_class = knn.predict([embedding])[0]\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn, train_embeddings, train_labels = training_embedding_label(facenet, train_loader, device, k=5)\n",
    "\n",
    "image_path = \"../../../ChimpRec-Dataset/Chimpanzee_recognition_dataset/val/JEJE/JEJE_8.jpg\"\n",
    "predicted_class = predict(facenet, knn, image_path, transform, device)\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la préçision de la classifiactio grâçe à un k-NN classificateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def train_model_with_knn(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, k=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-----------------------\")\n",
    "\n",
    "        # Phase d'entraînement\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for anchor, positive, negative in train_loader:\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_output = model(anchor)\n",
    "            positive_output = model(positive)\n",
    "            negative_output = model(negative)\n",
    "\n",
    "            loss = criterion(anchor_output, positive_output, negative_output)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Phase de validation avec Triplet Loss\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for anchor, positive, negative in val_loader:\n",
    "                anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "                anchor_output = model(anchor)\n",
    "                positive_output = model(positive)\n",
    "                negative_output = model(negative)\n",
    "\n",
    "                loss = criterion(anchor_output, positive_output, negative_output)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        \n",
    "\n",
    "train_model(facenet, train_loader, val_loader, criterion, optimizer, num_epochs=10, k=10)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
