{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = \"../../../ChimpRec-Dataset/CCR/data/videos\"\n",
    "annotations_path = \"../../../ChimpRec-Dataset/CCR/annotations/face_data.csv\"\n",
    "dataset_path = \"../../../ChimpRec-Dataset/Chimpanzee_recognition_dataset\"\n",
    "train_path = f\"{dataset_path}/train\"\n",
    "val_path = f\"{dataset_path}/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeped_ind = [\"JOYA\", \"FLANLE\", \"FANLE\", \"JEJE\", \"PELEY\", \"FANWA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59951\n",
      "106096\n",
      "149942\n",
      "189896\n",
      "74550\n",
      "58635\n"
     ]
    }
   ],
   "source": [
    "for name in keeped_ind: \n",
    "    print(len(annotations.loc[annotations[\"label\"] == name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JOYA':          year                     video   frame  track         x         y  \\\n",
      "262473   2012        20120202150041.mp4   12920    208  0.316978  0.228145   \n",
      "121006   2012        20120201093157.mp4    7610    207  0.910153  0.400579   \n",
      "196533   2012        20120201093157.mp4   39851   1495  0.743803  0.235253   \n",
      "688993   2012        20120202150041.mp4  147639   3956  0.389984  0.719781   \n",
      "1222196  2012  20120210142221_PAB20.mp4    8091    238  0.793144  0.258318   \n",
      "...       ...                       ...     ...    ...       ...       ...   \n",
      "108406   2012        20120201093157.mp4     988     23  0.661204  0.594388   \n",
      "280500   2012        20120202150041.mp4   21494    435  0.671516  0.213948   \n",
      "269064   2012        20120202150041.mp4   15216    230  0.561243  0.303439   \n",
      "1222783  2012  20120210142221_PAB20.mp4    8680    242  0.513293  0.344040   \n",
      "1244769  2012  20120210142221_PAB20.mp4   17475    431  0.493516  0.080117   \n",
      "\n",
      "                w         h label  \n",
      "262473   0.109348  0.198480  JOYA  \n",
      "121006   0.105847  0.174575  JOYA  \n",
      "196533   0.042146  0.152352  JOYA  \n",
      "688993   0.030574  0.055651  JOYA  \n",
      "1222196  0.060804  0.092080  JOYA  \n",
      "...           ...       ...   ...  \n",
      "108406   0.026928  0.069453  JOYA  \n",
      "280500   0.082051  0.155962  JOYA  \n",
      "269064   0.049422  0.184596  JOYA  \n",
      "1222783  0.064017  0.114533  JOYA  \n",
      "1244769  0.040003  0.079567  JOYA  \n",
      "\n",
      "[900 rows x 9 columns], 'FLANLE':          year               video   frame  track         x         y  \\\n",
      "1797043  2013               4.mp4   19719     43  0.665280  0.392246   \n",
      "515986   2012  20120202150041.mp4   95453   2490  0.440486  0.382142   \n",
      "1110725  2012  20120209145326.mp4   25398    974  0.553486  0.337433   \n",
      "1721184  2013               3.mp4    7094     73  0.865734  0.345477   \n",
      "1718040  2013               3.mp4    6572     73  0.819689  0.483593   \n",
      "...       ...                 ...     ...    ...       ...       ...   \n",
      "618863   2012  20120202150041.mp4  128356   3333  0.081019  0.324056   \n",
      "1068365  2012  20120209145326.mp4   13312    480  0.142866  0.598761   \n",
      "540071   2012  20120202150041.mp4  101922   2692  0.353021  0.261222   \n",
      "618708   2012  20120202150041.mp4  128325   3333  0.083544  0.324490   \n",
      "1793533  2013               4.mp4   17964     43  0.602583  0.315988   \n",
      "\n",
      "                w         h   label  \n",
      "1797043  0.079363  0.133838  FLANLE  \n",
      "515986   0.064125  0.087079  FLANLE  \n",
      "1110725  0.069039  0.131041  FLANLE  \n",
      "1721184  0.075808  0.130054  FLANLE  \n",
      "1718040  0.081067  0.153774  FLANLE  \n",
      "...           ...       ...     ...  \n",
      "618863   0.072869  0.094331  FLANLE  \n",
      "1068365  0.026897  0.062279  FLANLE  \n",
      "540071   0.094125  0.112259  FLANLE  \n",
      "618708   0.072423  0.095129  FLANLE  \n",
      "1793533  0.080315  0.130749  FLANLE  \n",
      "\n",
      "[900 rows x 9 columns], 'FANLE':          year                     video   frame  track         x         y  \\\n",
      "1544563  2013                    13.mp4    6261    102  0.467589  0.297766   \n",
      "576084   2012        20120202150041.mp4  115994   3085  0.319202  0.376845   \n",
      "1066592  2012        20120209145326.mp4   12936    457  0.371455  0.360075   \n",
      "658059   2012        20120202150041.mp4  139314   3629  0.758433  0.440978   \n",
      "1504805  2013                    12.mp4    7761     57  0.677210  0.415385   \n",
      "...       ...                       ...     ...    ...       ...       ...   \n",
      "1500873  2013                    12.mp4    6545     38  0.673322  0.347554   \n",
      "1454836  2012  20120210142221_PAB20.mp4   82656   1844  0.233861  0.416196   \n",
      "1490697  2013                    12.mp4    2594     12  0.514693  0.390219   \n",
      "152298   2012        20120201093157.mp4   19738    696  0.738825  0.017428   \n",
      "1114243  2012        20120209145326.mp4   26399    954  0.677155  0.287620   \n",
      "\n",
      "                w         h  label  \n",
      "1544563  0.054743  0.110940  FANLE  \n",
      "576084   0.070473  0.129729  FANLE  \n",
      "1066592  0.048518  0.098964  FANLE  \n",
      "658059   0.067315  0.110969  FANLE  \n",
      "1504805  0.046710  0.093438  FANLE  \n",
      "...           ...       ...    ...  \n",
      "1500873  0.102666  0.167118  FANLE  \n",
      "1454836  0.087388  0.175907  FANLE  \n",
      "1490697  0.122637  0.207645  FANLE  \n",
      "152298   0.075047  0.124537  FANLE  \n",
      "1114243  0.070980  0.191119  FANLE  \n",
      "\n",
      "[900 rows x 9 columns], 'JEJE':          year                     video  frame  track         x         y  \\\n",
      "1786448  2013                     4.mp4  14721     36 -0.015405  0.407317   \n",
      "1042014  2012        20120209145326.mp4   2392    120  0.597732  0.124873   \n",
      "1045306  2012        20120209145326.mp4   5340    219  0.853038  0.335866   \n",
      "1318888  2012  20120210142221_PAB20.mp4  37073    980  0.806249  0.234422   \n",
      "1709393  2013                     3.mp4   4924     48  0.333893  0.253449   \n",
      "...       ...                       ...    ...    ...       ...       ...   \n",
      "1048961  2012        20120209145326.mp4   6760    219  0.849682  0.347028   \n",
      "1376153  2012  20120210142221_PAB20.mp4  52642   1346  0.761660  0.701884   \n",
      "1354033  2012  20120210142221_PAB20.mp4  48683   1265  0.767776  0.703820   \n",
      "1039012  2012        20120209145326.mp4   1086     16  0.369946  0.362116   \n",
      "1073279  2012        20120209145326.mp4  14301    466  0.671317  0.425348   \n",
      "\n",
      "                w         h label  \n",
      "1786448  0.079943  0.193035  JEJE  \n",
      "1042014  0.092262  0.183725  JEJE  \n",
      "1045306  0.043894  0.136607  JEJE  \n",
      "1318888  0.090048  0.185517  JEJE  \n",
      "1709393  0.095289  0.213795  JEJE  \n",
      "...           ...       ...   ...  \n",
      "1048961  0.044784  0.144049  JEJE  \n",
      "1376153  0.048678  0.082070  JEJE  \n",
      "1354033  0.048914  0.090375  JEJE  \n",
      "1039012  0.091913  0.191235  JEJE  \n",
      "1073279  0.046697  0.078145  JEJE  \n",
      "\n",
      "[900 rows x 9 columns], 'PELEY':          year                    video  frame  track         x         y  \\\n",
      "860881   2012  20120205071109-PAB9.mp4  26075    294  0.595135  0.211049   \n",
      "945885   2012  20120205071109-PAB9.mp4  60596    933  0.630870  0.375864   \n",
      "19730    2012       20120121160715.mp4   4806    225  0.527467  0.375652   \n",
      "758853   2012  20120204170938-PAB8.mp4  26136    428  0.293230  0.287457   \n",
      "793350   2012  20120204170938-PAB8.mp4  38370    598  0.586275  0.548815   \n",
      "...       ...                      ...    ...    ...       ...       ...   \n",
      "1191646  2012       20120209145326.mp4  50902   1721  0.385037  0.516191   \n",
      "854186   2012  20120205071109-PAB9.mp4  23323    262  0.598049  0.178739   \n",
      "845012   2012  20120205071109-PAB9.mp4  20654    223  0.593267  0.225851   \n",
      "824351   2012  20120205071109-PAB9.mp4  14022    116  0.566676  0.190581   \n",
      "51514    2012       20120121160715.mp4  15961    621  0.397898  0.164452   \n",
      "\n",
      "                w         h  label  \n",
      "860881   0.085292  0.198448  PELEY  \n",
      "945885   0.051871  0.146358  PELEY  \n",
      "19730    0.057854  0.093809  PELEY  \n",
      "758853   0.023391  0.088576  PELEY  \n",
      "793350   0.059763  0.107259  PELEY  \n",
      "...           ...       ...    ...  \n",
      "1191646  0.039648  0.109991  PELEY  \n",
      "854186   0.082664  0.186639  PELEY  \n",
      "845012   0.087260  0.194855  PELEY  \n",
      "824351   0.105363  0.184979  PELEY  \n",
      "51514    0.098869  0.187238  PELEY  \n",
      "\n",
      "[900 rows x 9 columns], 'FANWA':          year                     video   frame  track         x         y  \\\n",
      "1511031  2013                    12.mp4   10345    109  0.446541  0.536016   \n",
      "1491271  2013                    12.mp4    3023     28  0.467086  0.538892   \n",
      "1722734  2013                     3.mp4    7377     76  0.598763  0.310033   \n",
      "123593   2012        20120201093157.mp4    8546    229  0.308687  0.168725   \n",
      "669129   2012        20120202150041.mp4  142979   3830  0.945000  0.453694   \n",
      "...       ...                       ...     ...    ...       ...       ...   \n",
      "1475117  2013                    11.mp4    9359     69  0.770986  0.468881   \n",
      "1747884  2013                     3.mp4   14384    260  0.733602  0.502518   \n",
      "1457626  2012  20120210142221_PAB20.mp4   83448   1860  0.577711  0.579461   \n",
      "1587433  2013                    14.mp4    8671    111  0.689227  0.576849   \n",
      "1519552  2013                    12.mp4   12849    129  0.413692  0.475801   \n",
      "\n",
      "                w         h  label  \n",
      "1511031  0.031427  0.087904  FANWA  \n",
      "1491271  0.105355  0.146582  FANWA  \n",
      "1722734  0.060291  0.094978  FANWA  \n",
      "123593   0.059229  0.069231  FANWA  \n",
      "669129   0.027769  0.041471  FANWA  \n",
      "...           ...       ...    ...  \n",
      "1475117  0.090896  0.137243  FANWA  \n",
      "1747884  0.050809  0.057792  FANWA  \n",
      "1457626  0.062287  0.103007  FANWA  \n",
      "1587433  0.037946  0.086471  FANWA  \n",
      "1519552  0.084098  0.142972  FANWA  \n",
      "\n",
      "[900 rows x 9 columns]}\n"
     ]
    }
   ],
   "source": [
    "train_set = {}\n",
    "val_set = {}\n",
    "\n",
    "for name in keeped_ind:\n",
    "    individual_annotations = annotations[annotations[\"label\"] == name]\n",
    "    \n",
    "    selected_samples = individual_annotations.sample(n=1000, random_state=42)\n",
    "\n",
    "    train_samples, val_samples = train_test_split(selected_samples, test_size=0.1, random_state=42)\n",
    "    \n",
    "    train_set[name] = train_samples\n",
    "    val_set[name] = val_samples\n",
    "\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(dataset_path, exist_ok=True)\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(video_path, frame_number): \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Impossible de lire la vidéo : {video_path}\")\n",
    "        return \n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if frame_number >= total_frames:\n",
    "        print(f\"Frame {frame_number} hors limites pour la vidéo {video_path}. Total frames: {total_frames}\")\n",
    "        cap.release()\n",
    "        return \n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret or frame is None or frame.size == 0:\n",
    "        print(f\"Erreur lors de la lecture de la frame {frame_number} pour {video_path}\")\n",
    "        return \n",
    "    return frame\n",
    "\n",
    "\n",
    "def get_coordinate(x,y,w,h,img_W,img_H): \n",
    "    x = max(0, min(x, 1))\n",
    "    y = max(0, min(y, 1))\n",
    "    w = max(0, min(w, 1))\n",
    "    h = max(0, min(h, 1))\n",
    "\n",
    "    x1 = max(0, int(x * img_W))\n",
    "    y1 = max(0, int(y * img_H))\n",
    "    x2 = min(img_W, int((x + w) * img_W))\n",
    "    y2 = min(img_H, int((y + h) * img_H))\n",
    "    return x1,y1,x2,y2\n",
    "\n",
    "\n",
    "def get_cropped_frame(frame, x1,y1,x2,y2,video_path,frame_number): \n",
    "    cropped_frame = frame[y1:y2, x1:x2]\n",
    "    if cropped_frame.size == 0:\n",
    "        print(f\"Image vide pour {video_path}, frame {frame_number}\")\n",
    "        return \n",
    "    \n",
    "    return Image.fromarray(cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "def save_images_to_structure(df, output_dir, name):\n",
    "    num = 1\n",
    "    for _, face in df.iterrows():\n",
    "        year = face['year']\n",
    "        video = face['video']\n",
    "        frame_number = face['frame']\n",
    "        x, y, w, h = face['x'], face['y'], face['w'], face['h']\n",
    "\n",
    "        video_path = f\"{videos_path}/{year}/{video}\"\n",
    "        frame = get_frame(video_path, frame_number)\n",
    "\n",
    "        x1,y1,x2,y2 = get_coordinate(x,y,w,h,frame.shape[1],frame.shape[0])\n",
    "        \n",
    "        cropped_image = get_cropped_frame(frame, x1,y1,x2,y2,video_path,frame_number)\n",
    "\n",
    "        image_path = f\"{output_dir}/{name}_{num}.jpg\"\n",
    "        cropped_image.save(image_path)\n",
    "        num += 1\n",
    "\n",
    "\n",
    "for name, chimp_df in train_set.items():\n",
    "    chimp_path = f\"{train_path}/{name}\"\n",
    "    os.makedirs(chimp_path, exist_ok=True)\n",
    "    save_images_to_structure(chimp_df, chimp_path, name)\n",
    "\n",
    "for name, chimp_df in val_set.items():\n",
    "    chimp_path = f\"{val_path}/{name}\"\n",
    "    os.makedirs(chimp_path, exist_ok=True)\n",
    "    save_images_to_structure(chimp_df, chimp_path, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv_data = []\\n\\nfor index, face in final_df.iterrows():\\n    print(index)\\n    year = face[\\'year\\']\\n    video = face[\\'video\\']  \\n    frame_number = face[\\'frame\\']\\n    track_id = face[\\'track\\']\\n    x, y, w, h = face[\\'x\\'], face[\\'y\\'], face[\\'w\\'], face[\\'h\\']\\n    label = face[\\'label\\']\\n\\n    video_path = f\"{videos_path}/{year}/{video}\"\\n    cap = cv2.VideoCapture(video_path)\\n    if not cap.isOpened():\\n        print(f\"Impossible de lire la vidéo : {video_path}\")\\n    else:\\n        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\\n        if frame_number >= total_frames:\\n            print(f\"Frame {frame_number} est hors des limites pour la vidéo {video_path}. Total frames: {total_frames}\")\\n            cap.release()\\n            continue\\n        \\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\\n\\n        ret, frame = cap.read()\\n\\n        if not ret:\\n            print(f\"Impossible de lire la frame {frame_number} dans la vidéo {video_path}\")\\n            cap.release()\\n            continue \\n\\n        cap.release()\\n\\n        if frame is None or frame.size == 0:\\n            print(f\"Frame vide lue pour {video_path} à la frame {frame_number}\")\\n            continue \\n\\n        img_W, img_H = frame.shape[1], frame.shape[0]\\n\\n        x = max(0, min(x, 1)) \\n        y = max(0, min(y, 1)) \\n        w = max(0, min(w, 1))\\n        h = max(0, min(h, 1))\\n\\n        x1 = max(0, int(x * img_W))\\n        y1 = max(0, int(y * img_H))\\n        x2 = min(img_W, int((x + w) * img_W))\\n        y2 = min(img_H, int((y + h) * img_H))\\n        \\n        cropped_frame = frame[y1:y2, x1:x2]\\n            \\n        cropped_image = Image.fromarray(cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB))\\n\\n        image_path = f\"{dataset_path}/{index}.jpg\"\\n        cropped_image.save(image_path)\\n\\n        csv_data.append({\\n            \\'index\\': index,\\n            \\'label\\': label,\\n            \\'image_path\\': image_path\\n        })\\n\\ncsv_df = pd.DataFrame(csv_data)\\ncsv_df.to_csv(f\"{dataset_path}/video_face_mapping.csv\", index=False)\\nprint(\"CSV créé et images sauvegardées.\")\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"csv_data = []\n",
    "\n",
    "for index, face in final_df.iterrows():\n",
    "    print(index)\n",
    "    year = face['year']\n",
    "    video = face['video']  \n",
    "    frame_number = face['frame']\n",
    "    track_id = face['track']\n",
    "    x, y, w, h = face['x'], face['y'], face['w'], face['h']\n",
    "    label = face['label']\n",
    "\n",
    "    video_path = f\"{videos_path}/{year}/{video}\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Impossible de lire la vidéo : {video_path}\")\n",
    "    else:\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        if frame_number >= total_frames:\n",
    "            print(f\"Frame {frame_number} est hors des limites pour la vidéo {video_path}. Total frames: {total_frames}\")\n",
    "            cap.release()\n",
    "            continue\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(f\"Impossible de lire la frame {frame_number} dans la vidéo {video_path}\")\n",
    "            cap.release()\n",
    "            continue \n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Frame vide lue pour {video_path} à la frame {frame_number}\")\n",
    "            continue \n",
    "\n",
    "        img_W, img_H = frame.shape[1], frame.shape[0]\n",
    "\n",
    "        x = max(0, min(x, 1)) \n",
    "        y = max(0, min(y, 1)) \n",
    "        w = max(0, min(w, 1))\n",
    "        h = max(0, min(h, 1))\n",
    "\n",
    "        x1 = max(0, int(x * img_W))\n",
    "        y1 = max(0, int(y * img_H))\n",
    "        x2 = min(img_W, int((x + w) * img_W))\n",
    "        y2 = min(img_H, int((y + h) * img_H))\n",
    "        \n",
    "        cropped_frame = frame[y1:y2, x1:x2]\n",
    "            \n",
    "        cropped_image = Image.fromarray(cv2.cvtColor(cropped_frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        image_path = f\"{dataset_path}/{index}.jpg\"\n",
    "        cropped_image.save(image_path)\n",
    "\n",
    "        csv_data.append({\n",
    "            'index': index,\n",
    "            'label': label,\n",
    "            'image_path': image_path\n",
    "        })\n",
    "\n",
    "csv_df = pd.DataFrame(csv_data)\n",
    "csv_df.to_csv(f\"{dataset_path}/video_face_mapping.csv\", index=False)\n",
    "print(\"CSV créé et images sauvegardées.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for index, row in annotations.iterrows():\\n    video_path = row['ideo']  # Chemin ou identifiant de la vidéo\\n    frame_number = row['frame']  # Numéro de la frame\\n    track_id = row['track']\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for index, row in annotations.iterrows():\n",
    "    video_path = row['ideo']  # Chemin ou identifiant de la vidéo\n",
    "    frame_number = row['frame']  # Numéro de la frame\n",
    "    track_id = row['track']\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
