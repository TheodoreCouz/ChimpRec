{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/videos\"\n",
    "annotations_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/CCR/metadata/annotations/body_data.csv\"\n",
    "dataset_path = \"/home/theo/Documents/Unif/Master/ChimpRec/ChimpRec-Dataset/Chimpanzee_detection_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year   video  frame  track         x         y         w         h  \\\n",
      "1652518  2013  17.mp4    957      3  0.143538  0.159027  0.020601  0.072732   \n",
      "1652519  2013  17.mp4    958      3  0.143447  0.159946  0.020592  0.072688   \n",
      "1652520  2013  17.mp4    959      3  0.143356  0.160865  0.020582  0.072644   \n",
      "1652521  2013  17.mp4    960      3  0.143264  0.161785  0.020573  0.072600   \n",
      "1652522  2013  17.mp4    961      3  0.143173  0.162704  0.020564  0.072557   \n",
      "...       ...     ...    ...    ...       ...       ...       ...       ...   \n",
      "1661293  2013  17.mp4   6526     16  0.098948  0.572017  0.034380  0.059375   \n",
      "1661294  2013  17.mp4   6527     16  0.098759  0.570864  0.034378  0.061506   \n",
      "1661295  2013  17.mp4   6528     16  0.097701  0.570297  0.035872  0.060066   \n",
      "1661296  2013  17.mp4   6529     16  0.099128  0.570533  0.034480  0.060810   \n",
      "1661297  2013  17.mp4   6530     16  0.098881  0.570130  0.034788  0.060924   \n",
      "\n",
      "            label  \n",
      "1652518  NEGATIVE  \n",
      "1652519  NEGATIVE  \n",
      "1652520  NEGATIVE  \n",
      "1652521  NEGATIVE  \n",
      "1652522  NEGATIVE  \n",
      "...           ...  \n",
      "1661293      JIRE  \n",
      "1661294      JIRE  \n",
      "1661295      JIRE  \n",
      "1661296      JIRE  \n",
      "1661297      JIRE  \n",
      "\n",
      "[8780 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations_path)\n",
    "print(df.loc[df[\"video\"] == \"17.mp4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_kept = 0.0015 # approximately 1500 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input: n: size of the sample\n",
    "# proportion: (proportion*100)% of the numbers in [0, n-1]\n",
    "# @outputs\n",
    "# No numbers in common between the outputs\n",
    "def segment_dataset(n, proportion):\n",
    "    # Calculate the number of elements to select based on the proportion\n",
    "    num_elements = int(n * proportion)\n",
    "\n",
    "    # Generate evenly spaced numbers within the range [0, n-1]\n",
    "    step = n / num_elements\n",
    "    selected_numbers = [int(i * step) for i in range(num_elements)]\n",
    "    \n",
    "    return selected_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len_video(path_to_video):\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{path_to_video}\")\n",
    "\n",
    "    if not video.isOpened():\n",
    "        print(f\"Could not open video: {path_to_video}\")\n",
    "        return 0\n",
    "    \n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video.release()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_coordinates(coord, img_width, img_height):\n",
    "\n",
    "    x, y, w, h = coord\n",
    "    \n",
    "    x1 = int(x*img_width)\n",
    "    y1 = int(y*img_width)\n",
    "    x2 = int(x*img_width+w*img_width)\n",
    "    y2 = int((y*img_width)+h*img_height)\n",
    "\n",
    "    cx = (x1 + x2) / 2\n",
    "    cy = (y1 + y2) / 2\n",
    "\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    cx_norm = cx / img_width\n",
    "    cy_norm = cy / img_height\n",
    "\n",
    "    width_norm = width / img_width\n",
    "    height_norm = height / img_height\n",
    "\n",
    "    return [cx_norm, cy_norm, width_norm, height_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(video_type, video_id, frame_number, img_dim):\n",
    "    img_W, img_H = img_dim\n",
    "    sample_id = video_id.replace(\".mp4\", \"\")\n",
    "    sub_df = df.loc[(df[\"video\"] == video_id) & (df[\"frame\"] == frame_number)]\n",
    "    output_file = f\"{dataset_path}/labels/{video_type}/{sample_id}_{frame_number}.txt\"\n",
    "\n",
    "    string_output = \"\"\n",
    "\n",
    "    for index, row in sub_df.iterrows():\n",
    "        x, y, w, h = row['x'], row['y'], row['w'], row['h']\n",
    "        cx, cy, W, H = preprocess_coordinates((x, y, w, h), img_W, img_H)\n",
    "        string_output += f\"\\n0 {cx} {cy} {W} {H}\"\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(string_output.strip())\n",
    "    file.close()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @input:\n",
    "# type: \"train\", \"val\" or \"test\" --> indicates which part of the dataset it is\n",
    "# sample_id: name of the video with the extension\n",
    "# idxs: indexes of the images to keep\n",
    "# @output:\n",
    "# nothing, the image are saved in the output folder\n",
    "def extract_data(type, video_id):\n",
    "\n",
    "    sample_id = video_id[:-4]\n",
    "\n",
    "    output_folder = f\"{dataset_path}/images/{type}\"\n",
    "    video = cv2.VideoCapture(f\"{video_path}/{video_id}\")\n",
    "    len_video = get_len_video(video_id)\n",
    "\n",
    "    idxs = segment_dataset(len_video, proportion_kept)\n",
    "    idxs = sorted(idxs)\n",
    "\n",
    "    for frame_count in idxs:\n",
    "        df_ = df.loc[df[\"video\"] == video_id]\n",
    "        df_ = df_.loc[df_[\"frame\"] == frame_count] # .loc[df[\"label\"] != \"NOTCHIMP\"]\n",
    "\n",
    "        # Set the video to the specific frame\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "        success, frame = video.read()\n",
    "\n",
    "        if success and df_.size != 0:\n",
    "            frame_filename = f\"{output_folder}/{sample_id}_{frame_count}.jpg\"\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            \n",
    "            # extract the annotations\n",
    "            extract_metadata(type, video_id, frame_count, (frame.shape[1], frame.shape[0]))\n",
    "        # else:\n",
    "        #     print(f\"Could not read frame {frame_count} in video {video_id}\")\n",
    "        #     print(df_)\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(video_path)\n",
    "n_files = len(filenames)\n",
    "\n",
    "train_prop = 0.85\n",
    "\n",
    "numbers = list(range(n_files))\n",
    "random.shuffle(numbers)\n",
    "\n",
    "train_video_idxs = numbers[:math.ceil(train_prop*n_files)]\n",
    "val_video_idxs = numbers[math.ceil(train_prop*n_files):]\n",
    "\n",
    "def process_dataset(video_idxs, type):\n",
    "    # progression bar added\n",
    "    for video_idx in tqdm(video_idxs, desc=f\"Processing videos: {type}\", colour=\"green\"):\n",
    "        video_id = filenames[video_idx]\n",
    "        # try:\n",
    "        #     extract_data(type, video_id)\n",
    "        # except:\n",
    "        #     print(f\"Error: {video_id}\")\n",
    "        extract_data(type, video_id)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:   0%|\u001b[32m          \u001b[0m| 0/23 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120201091719.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:   4%|\u001b[32m▍         \u001b[0m| 1/23 [00:04<01:46,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120121160715.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:   9%|\u001b[32m▊         \u001b[0m| 2/23 [00:16<03:10,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  13%|\u001b[32m█▎        \u001b[0m| 3/23 [00:18<01:51,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  17%|\u001b[32m█▋        \u001b[0m| 4/23 [00:24<01:52,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120209145326.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  22%|\u001b[32m██▏       \u001b[0m| 5/23 [00:52<04:09, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120205165846-PAB11.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  26%|\u001b[32m██▌       \u001b[0m| 6/23 [01:08<04:09, 14.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  35%|\u001b[32m███▍      \u001b[0m| 8/23 [01:13<01:57,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120205154955-PAB10.mp4\n",
      "15.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  39%|\u001b[32m███▉      \u001b[0m| 9/23 [01:19<01:40,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  43%|\u001b[32m████▎     \u001b[0m| 10/23 [01:23<01:22,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120201093157.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  48%|\u001b[32m████▊     \u001b[0m| 11/23 [01:47<02:19, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  52%|\u001b[32m█████▏    \u001b[0m| 12/23 [01:48<01:33,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120205071109-PAB9.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  57%|\u001b[32m█████▋    \u001b[0m| 13/23 [02:24<02:47, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  61%|\u001b[32m██████    \u001b[0m| 14/23 [02:26<01:49, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  65%|\u001b[32m██████▌   \u001b[0m| 15/23 [02:28<01:14,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120202150041.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  70%|\u001b[32m██████▉   \u001b[0m| 16/23 [03:37<03:10, 27.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  74%|\u001b[32m███████▍  \u001b[0m| 17/23 [03:42<02:02, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120204170938-PAB8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  78%|\u001b[32m███████▊  \u001b[0m| 18/23 [03:58<01:35, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120210142221_PAB20.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  83%|\u001b[32m████████▎ \u001b[0m| 19/23 [04:38<01:41, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20120201085218.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  87%|\u001b[32m████████▋ \u001b[0m| 20/23 [04:39<00:54, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  91%|\u001b[32m█████████▏\u001b[0m| 21/23 [04:42<00:26, 13.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train:  96%|\u001b[32m█████████▌\u001b[0m| 22/23 [04:44<00:10, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: train: 100%|\u001b[32m██████████\u001b[0m| 23/23 [04:47<00:00, 12.49s/it]\n",
      "Processing videos: val:   0%|\u001b[32m          \u001b[0m| 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: val:  25%|\u001b[32m██▌       \u001b[0m| 1/4 [00:01<00:04,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: val:  50%|\u001b[32m█████     \u001b[0m| 2/4 [00:06<00:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: val:  75%|\u001b[32m███████▌  \u001b[0m| 3/4 [00:10<00:03,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: val: 100%|\u001b[32m██████████\u001b[0m| 4/4 [00:14<00:00,  3.59s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dataset(train_video_idxs, \"train\")\n",
    "process_dataset(val_video_idxs, \"val\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
