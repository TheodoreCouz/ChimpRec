{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test set path</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Theo/Documents/Unif/ChimpRec/Code\")\n",
    "\n",
    "\n",
    "from chimplib.metric import *\n",
    "from chimplib.imports import os, cv2, plt\n",
    "\n",
    "test_set = \"...\" #insert path\n",
    "model_path = \"...\" #insert path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generic function to compute intersection over union.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46731805220968897\n",
      "0.46922246572820714\n",
      "0.4679501297992655\n",
      "0.4777199233072285\n"
     ]
    }
   ],
   "source": [
    "print(iou([0.386891, 0.573836, 0.274225, 0.328799], [0.324225, 0.497304, 0.400000, 0.482353])) # BIG\n",
    "print(iou([0.670643, 0.656066, 0.136706, 0.164583], [0.639254, 0.618382, 0.199631, 0.240196])) # MEDIUM\n",
    "print(iou([0.820532, 0.697243, 0.068833, 0.082230], [0.805022, 0.678125, 0.100000, 0.120956])) # SMALL\n",
    "print(iou([0.902880, 0.717892, 0.033973, 0.040931], [0.895362, 0.709050, 0.049453, 0.058860])) # TINY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46785733580791994\n",
      "0.5542859293230449\n",
      "0.6885386459194439\n",
      "0.749347676802334\n"
     ]
    }
   ],
   "source": [
    "print(weighted_iou([0.386891, 0.573836, 0.274225, 0.328799], [0.324225, 0.497304, 0.400000, 0.482353])) # BIG\n",
    "print(weighted_iou([0.670643, 0.656066, 0.136706, 0.164583], [0.639254, 0.618382, 0.199631, 0.240196])) # MEDIUM\n",
    "print(weighted_iou([0.820532, 0.697243, 0.068833, 0.082230], [0.805022, 0.678125, 0.100000, 0.120956])) # SMALL\n",
    "print(weighted_iou([0.902880, 0.717892, 0.033973, 0.040931], [0.895362, 0.709050, 0.049453, 0.058860])) # TINY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30924394992000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_covered([0.267645, 0.307458, 0.523305, 0.590944], (1080, 1920))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:green;\">Test of the <i>iou</i> function.</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(observed, expected, test_name=\"\"):\n",
    "    msg = f'({test_name}): Observed: {observed}; Expected: {expected}'\n",
    "    if (round(observed, 5) == round(expected, 5)): print(f\"Test passed ({test_name})\")\n",
    "    else: print(f\"Test failed{msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed (Perfect Overlap)\n",
      "Test passed (No Overlap)\n",
      "Test passed (No Overlap)\n"
     ]
    }
   ],
   "source": [
    "bbox = [0.1, 0.1, 0.2, 0.2]\n",
    "test(iou(bbox, bbox), 1, \"Perfect Overlap\") # perfect overlap\n",
    "\n",
    "bbox2 = [0.9, 0.9, 0.1, 0.1] \n",
    "test(iou(bbox, bbox2), 0, \"No Overlap\") # no overlap\n",
    "\n",
    "bbox3 = [0.1, 0.2, 0.2, 0.2] \n",
    "test(iou(bbox, bbox3), 1/3, \"No Overlap\") # no overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computation of the following metrics based on the ground truth (from the test set) and the predictions</h2>\n",
    "<h3>\n",
    "    <ul>\n",
    "        <li>True Positive</li>\n",
    "        <li>False Positive</li>\n",
    "        <li><span style=\"color:grey;\">True Negative: not counted (see below)</span></li>\n",
    "        <li>False Negative</li>\n",
    "    </ul> \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:green;\">Test of the <i>extract_metrics</i> function.</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------\n",
      "Test passed (perfect match (TP))\n",
      "Test passed (perfect match (FP))\n",
      "Test passed (perfect match (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (No overlap (TP))\n",
      "Test passed (No overlap (FP))\n",
      "Test passed (No overlap (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (No overlap but bboxes are closer (TP))\n",
      "Test passed (No overlap but bboxes are closer (FP))\n",
      "Test passed (No overlap but bboxes are closer (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (Not a perfect match but above threshold (TP))\n",
      "Test passed (Not a perfect match but above threshold (FP))\n",
      "Test passed (Not a perfect match but above threshold (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (Two prediction bboxes matching the same ground truth (TP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (Two prediction bboxes matching the same ground truth (TP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (Two prediction bboxes matching the same ground truth (TP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FP))\n",
      "Test passed (Two prediction bboxes matching the same ground truth (FN))\n",
      "\n",
      "------------------------------------\n",
      "Test passed (GT completed included within prediction (TP))\n",
      "Test passed (GT completed included within prediction (FP))\n",
      "Test passed (GT completed included within prediction (FN))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------------------------------------\")\n",
    "# perfect match\n",
    "GT = {\"img1\": [[0.2, 0.2, 0.1, 0.1]]}\n",
    "PRED = {\"img1\": [[0.2, 0.2, 0.1, 0.1]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 1, \"perfect match (TP)\")\n",
    "test(fp, 0, \"perfect match (FP)\")\n",
    "test(fn, 0, \"perfect match (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# No overlap\n",
    "GT = {\"img2\": [[0.8, 0.8, 0.1, 0.1]]}\n",
    "PRED = {\"img2\": [[0.2, 0.2, 0.1, 0.1]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 0, \"No overlap (TP)\")\n",
    "test(fp, 1, \"No overlap (FP)\")\n",
    "test(fn, 1, \"No overlap (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# No overlap but bboxes are closer\n",
    "GT = {\"img3\": [[0.1, 0.1, 0.1, 0.1]]}\n",
    "PRED = {\"img3\": [[0.2, 0.2, 0.1, 0.1]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 0, \"No overlap but bboxes are closer (TP)\")\n",
    "test(fp, 1, \"No overlap but bboxes are closer (FP)\")\n",
    "test(fn, 1, \"No overlap but bboxes are closer (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# Not a perfect match but above threshold\n",
    "GT = {\"img4\": [[0.1, 0.1, 0.1, 0.1]]}\n",
    "PRED = {\"img4\": [[0.1, 0.1, 0.09, 0.09]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 1, \"Not a perfect match but above threshold (TP)\")\n",
    "test(fp, 0, \"Not a perfect match but above threshold (FP)\")\n",
    "test(fn, 0, \"Not a perfect match but above threshold (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# Two prediction bboxes matching the same ground truth\n",
    "GT = {\"img5\": [[0.1, 0.1, 0.1, 0.1]]}\n",
    "PRED = {\"img5\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 1, \"Two prediction bboxes matching the same ground truth (TP)\")\n",
    "test(fp, 1, \"Two prediction bboxes matching the same ground truth (FP)\")\n",
    "test(fn, 0, \"Two prediction bboxes matching the same ground truth (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# Composed case - 2 pred matching 1 GT - 1 pred matching 1 GT\n",
    "GT = {\"img6\": [[0.1, 0.1, 0.1, 0.1], [0.8, 0.8, 0.2, 0.3]]}\n",
    "PRED = {\"img6\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09], [0.8, 0.8, 0.18, 0.32]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 2, \"Two prediction bboxes matching the same ground truth (TP)\")\n",
    "test(fp, 1, \"Two prediction bboxes matching the same ground truth (FP)\")\n",
    "test(fn, 0, \"Two prediction bboxes matching the same ground truth (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# One prediction overlapping two ground truths\n",
    "GT = {\"img7\": [[0.269316, 0.482907, 0.351723, 0.377785], [0.369253, 0.815242, 0.354316, 0.346540]]}\n",
    "PRED = {\"img7\": [[0.367304, 0.808140, 0.362103, 0.366419]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 1, \"Two prediction bboxes matching the same ground truth (TP)\")\n",
    "test(fp, 0, \"Two prediction bboxes matching the same ground truth (FP)\")\n",
    "test(fn, 1, \"Two prediction bboxes matching the same ground truth (FN)\")\n",
    "\n",
    "print(\"\\n------------------------------------\")\n",
    "# GT completed included within prediction\n",
    "GT = {\"img8\": [[0.5, 0.5, 0.5, 0.5]]}\n",
    "PRED = {\"img8\": [[0.5, 0.5, 0.55, 0.55]]}\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 1, \"GT completed included within prediction (TP)\")\n",
    "test(fp, 0, \"GT completed included within prediction (FP)\")\n",
    "test(fn, 0, \"GT completed included within prediction (FN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:green;\">Combined test of the <i>extract_metrics</i> function.</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed (Combined test (TP))\n",
      "Test passed (Combined test (FP))\n",
      "Test passed (Combined test (FN))\n"
     ]
    }
   ],
   "source": [
    "GT = {\n",
    "    \"img1\": [[0.2, 0.2, 0.1, 0.1]], \n",
    "    \"img2\": [[0.8, 0.8, 0.1, 0.1]], \n",
    "    \"img3\": [[0.1, 0.1, 0.1, 0.1]],\n",
    "    \"img4\": [[0.1, 0.1, 0.1, 0.1]],\n",
    "    \"img5\": [[0.1, 0.1, 0.1, 0.1]],\n",
    "    \"img6\": [[0.1, 0.1, 0.1, 0.1], [0.8, 0.8, 0.2, 0.3]],\n",
    "    \"img7\": [[0.269316, 0.482907, 0.351723, 0.377785], [0.369253, 0.815242, 0.354316, 0.346540]]\n",
    "    }\n",
    "PRED = {\n",
    "    \"img1\": [[0.2, 0.2, 0.1, 0.1]],    # +1 TP\n",
    "    \"img2\": [[0.2, 0.2, 0.1, 0.1]],    # +1 FP, +1 FN\n",
    "    \"img3\": [[0.2, 0.2, 0.1, 0.1]],    # +1 FP, +1 FN\n",
    "    \"img4\": [[0.1, 0.1, 0.09, 0.09]],  # +1 TP --> not a perfect match but above threshold\n",
    "    \"img5\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09]], # +1 TP, +1 FP\n",
    "    \"img6\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09], [0.8, 0.8, 0.18, 0.32]], # +2 TP, +1 FP\n",
    "    \"img7\": [[0.367304, 0.808140, 0.362103, 0.366419]] # +1 TP, +1 FN\n",
    "    }\n",
    "\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 6, \"Combined test (TP)\")\n",
    "test(fp, 4, \"Combined test (FP)\")\n",
    "test(fn, 3, \"Combined test (FN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extract the data from the test set (to <i>dict</i>)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:green;\">Test of the <i>extract_ground_truth</i> function.</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed (Extract ground truth from files (TP))\n",
      "Test passed (Extract ground truth from files (FP))\n",
      "Test passed (Extract ground truth from files (FN))\n"
     ]
    }
   ],
   "source": [
    "GT = extract_ground_truth(test_set_path=\"test_set_example\")\n",
    "PRED = {\n",
    "    \"img1\": [[0.2, 0.2, 0.1, 0.1]],    # +1 TP\n",
    "    \"img2\": [[0.2, 0.2, 0.1, 0.1]],    # +1 FP, +1 FN\n",
    "    \"img3\": [[0.2, 0.2, 0.1, 0.1]],    # +1 FP, +1 FN\n",
    "    \"img4\": [[0.1, 0.1, 0.09, 0.09]],  # +1 TP --> not a perfect match but above threshold\n",
    "    \"img5\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09]], # +1 TP, +1 FP\n",
    "    \"img6\": [[0.1, 0.1, 0.1, 0.1], [0.1, 0.1, 0.09, 0.09], [0.8, 0.8, 0.18, 0.32]], # +2 TP, +1 FP\n",
    "    \"img7\": [[0.367304, 0.808140, 0.362103, 0.366419]] # +1 TP, +1 FN\n",
    "    }\n",
    "tp, fp, fn = extract_metrics(GT, PRED).values()\n",
    "test(tp, 6, \"Extract ground truth from files (TP)\")\n",
    "test(fp, 4, \"Extract ground truth from files (FP)\")\n",
    "test(fn, 3, \"Extract ground truth from files (FN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Effective code</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ground truth extraction.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = extract_ground_truth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predictions extraction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualisation functions.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(model_path, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualisation support</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# predictions = predict(model_path, test_set)\n",
    "draw_predictions(predictions, GT, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Computation of the model performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': 718, 'false_positives': 262, 'false_negatives': 475}\n",
      "precision=0.7326530612244898\n",
      "recall=0.6018440905280805\n"
     ]
    }
   ],
   "source": [
    "print(extract_metrics(GT, predictions, t=0.6))\n",
    "\n",
    "tp, fp, fn = extract_metrics(GT, predictions, t=0.6).values()\n",
    "print(f\"precision={tp/(tp+fp)}\")\n",
    "print(f\"recall={tp/(tp+fn)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
